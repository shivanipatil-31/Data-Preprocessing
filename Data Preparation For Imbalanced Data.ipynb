{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example for class imbalance\n",
    "\n",
    "Imbalanced Problem\n",
    "      \n",
    "      Imbalanced classes are a common problem in machine learning classification where there are a disproportionate ratio of observations in each class. Class imbalance can be found in many different areas including medical diagnosis, spam filtering, and fraud detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below code is for displaying the output from all lines of python code within a single cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# to display up to 500 rows in the output of the jupyter notebook cell\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the fraud dataset\n",
    "fraud_data = pd.read_csv(\"fraud_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59054, 434)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2994681</td>\n",
       "      <td>0</td>\n",
       "      <td>242834</td>\n",
       "      <td>25.000</td>\n",
       "      <td>H</td>\n",
       "      <td>9803</td>\n",
       "      <td>583.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>firefox 56.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1920x1080</td>\n",
       "      <td>match_status:2</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>desktop</td>\n",
       "      <td>rv:56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3557242</td>\n",
       "      <td>0</td>\n",
       "      <td>15123000</td>\n",
       "      <td>117.000</td>\n",
       "      <td>W</td>\n",
       "      <td>7919</td>\n",
       "      <td>194.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3327470</td>\n",
       "      <td>0</td>\n",
       "      <td>8378575</td>\n",
       "      <td>73.773</td>\n",
       "      <td>C</td>\n",
       "      <td>12778</td>\n",
       "      <td>500.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3118781</td>\n",
       "      <td>0</td>\n",
       "      <td>2607840</td>\n",
       "      <td>400.000</td>\n",
       "      <td>R</td>\n",
       "      <td>12316</td>\n",
       "      <td>548.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>195.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mobile safari generic</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1136x640</td>\n",
       "      <td>match_status:2</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>mobile</td>\n",
       "      <td>iOS Device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3459772</td>\n",
       "      <td>0</td>\n",
       "      <td>12226544</td>\n",
       "      <td>31.950</td>\n",
       "      <td>W</td>\n",
       "      <td>9002</td>\n",
       "      <td>453.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2994681        0         242834          25.000         H   9803   \n",
       "1        3557242        0       15123000         117.000         W   7919   \n",
       "2        3327470        0        8378575          73.773         C  12778   \n",
       "3        3118781        0        2607840         400.000         R  12316   \n",
       "4        3459772        0       12226544          31.950         W   9002   \n",
       "\n",
       "   card2  card3       card4  card5  ...                  id_31  id_32  \\\n",
       "0  583.0  150.0        visa  226.0  ...           firefox 56.0   24.0   \n",
       "1  194.0  150.0  mastercard  166.0  ...                    NaN    NaN   \n",
       "2  500.0  185.0  mastercard  224.0  ...                    NaN    NaN   \n",
       "3  548.0  150.0        visa  195.0  ...  mobile safari generic   32.0   \n",
       "4  453.0  150.0        visa  226.0  ...                    NaN    NaN   \n",
       "\n",
       "       id_33           id_34  id_35 id_36 id_37  id_38  DeviceType  DeviceInfo  \n",
       "0  1920x1080  match_status:2      T     F     T      T     desktop     rv:56.0  \n",
       "1        NaN             NaN    NaN   NaN   NaN    NaN         NaN         NaN  \n",
       "2        NaN             NaN    NaN   NaN   NaN    NaN         NaN         NaN  \n",
       "3   1136x640  match_status:2      T     F     T      F      mobile  iOS Device  \n",
       "4        NaN             NaN    NaN   NaN   NaN    NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 434 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the data\n",
    "print(fraud_data.shape)\n",
    "fraud_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    57049\n",
      "1     2005\n",
      "Name: isFraud, dtype: int64\n",
      "0    96.604802\n",
      "1     3.395198\n",
      "Name: isFraud, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zeenat\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='isFraud', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAASRElEQVR4nO3df4xdZX7f8fcn9hbIDwg/DCU2jVFwqwLZbIpLaFaNNuuquEpa0BZSJ91gpZZcIRolUpUE8kd+VZZA3XYbsgHJW3Yx5AdYbDc4UemWmmxWq1DD0JI1hiBGgYIDxWYhLKiCxM63f9xndq+H6+Haz9y5np33Szo6537Pec48xxr04XnOuWdSVUiSdLK+ZdodkCQtbwaJJKmLQSJJ6mKQSJK6GCSSpC6rp92BpXbeeefV+vXrp90NSVpWnnjiideqas2ofSsuSNavX8/MzMy0uyFJy0qS/3O8fU5tSZK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkrqsuG+2L4Yrfu6eaXdBp6An/v0N0+6CNBWOSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldJhokSV5Isj/Jk0lmWu2cJA8nea6tzx46/pYks0meTXL1UP2Kdp7ZJLcnSaufluT+Vt+XZP0kr0eS9F5LMSL54ar6UFVtbJ9vBvZW1QZgb/tMkkuBLcBlwGbgjiSrWps7ge3AhrZsbvVtwBtVdQnwSeC2JbgeSdKQaUxtXQPsatu7gGuH6vdV1btV9TwwC1yZ5ELgzKp6tKoKuGdem7lzPQBsmhutSJKWxqSDpID/nuSJJNtb7YKqegWgrc9v9bXAS0NtD7ba2rY9v35Mm6o6ArwJnDu/E0m2J5lJMnP48OFFuTBJ0sDqCZ//w1X1cpLzgYeT/OkCx44aSdQC9YXaHFuo2gnsBNi4ceN79kuSTt5ERyRV9XJbHwI+D1wJvNqmq2jrQ+3wg8BFQ83XAS+3+roR9WPaJFkNnAW8PolrkSSNNrEgSfJtSb5jbhv4x8BTwB5gaztsK/Bg294DbGlPYl3M4Kb6Y236660kV7X7HzfMazN3ruuAR9p9FEnSEpnk1NYFwOfbve/VwO9U1X9L8jiwO8k24EXgeoCqOpBkN/A0cAS4qaqOtnPdCNwNnAE81BaAu4B7k8wyGIlsmeD1SJJGmFiQVNWfAd83ov5VYNNx2uwAdoyozwCXj6i/QwsiSdJ0+M12SVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1mXiQJFmV5H8n+YP2+ZwkDyd5rq3PHjr2liSzSZ5NcvVQ/Yok+9u+25Ok1U9Lcn+r70uyftLXI0k61lKMSH4GeGbo883A3qraAOxtn0lyKbAFuAzYDNyRZFVrcyewHdjQls2tvg14o6ouAT4J3DbZS5EkzTfRIEmyDvgR4D8Pla8BdrXtXcC1Q/X7qurdqnoemAWuTHIhcGZVPVpVBdwzr83cuR4ANs2NViRJS2PSI5L/BPw88NdDtQuq6hWAtj6/1dcCLw0dd7DV1rbt+fVj2lTVEeBN4NxFvQJJ0oImFiRJfhQ4VFVPjNtkRK0WqC/UZn5ftieZSTJz+PDhMbsjSRrHJEckHwb+WZIXgPuAjyb5LeDVNl1FWx9qxx8ELhpqvw54udXXjagf0ybJauAs4PX5HamqnVW1sao2rlmzZnGuTpIETDBIquqWqlpXVesZ3ER/pKo+DuwBtrbDtgIPtu09wJb2JNbFDG6qP9amv95KclW7/3HDvDZz57qu/Yz3jEgkSZOzego/81Zgd5JtwIvA9QBVdSDJbuBp4AhwU1UdbW1uBO4GzgAeagvAXcC9SWYZjES2LNVFSJIGliRIquqLwBfb9leBTcc5bgewY0R9Brh8RP0dWhBJkqbDb7ZLkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSeoyVpAk2TtOTZK08qxeaGeS04FvBc5LcjaQtutM4Lsm3DdJ0jKwYJAA/xr4WQah8QTfCJKvAb85uW5JkpaLBYOkqn4d+PUkP11Vv7FEfZIkLSPvNyIBoKp+I8kPAuuH21TVPRPqlyRpmRgrSJLcC3wP8CRwtJULMEgkaYUbK0iAjcClVVWT7IwkafkZ93skTwF/c5IdkSQtT+MGyXnA00m+kGTP3LJQgySnJ3ksyZ8kOZDkV1v9nCQPJ3murc8eanNLktkkzya5eqh+RZL9bd/tSdLqpyW5v9X3JVl/wv8CkqQu405t/cpJnPtd4KNV9XaSDwBfTvIQ8DFgb1XdmuRm4GbgF5JcCmwBLmPwuPH/SPK3q+oocCewHfifwH8FNgMPAduAN6rqkiRbgNuAf3ESfZUknaRxn9r6oxM9cbuf8nb7+IG2FHAN8JFW3wV8EfiFVr+vqt4Fnk8yC1yZ5AXgzKp6FCDJPcC1DILkGr4Rcg8An0oS7+VI0tIZ9xUpbyX5WlveSXI0ydfGaLcqyZPAIeDhqtoHXFBVrwC09fnt8LXAS0PND7ba2rY9v35Mm6o6ArwJnDuiH9uTzCSZOXz48DiXLEka01hBUlXfUVVntuV04J8Dnxqj3dGq+hCwjsHo4vIFDs+IWi1QX6jN/H7srKqNVbVxzZo179NrSdKJOKm3/1bV7wEfPYHj/4LBFNZm4NUkFwK09aF22EHgoqFm64CXW33diPoxbZKsBs4CXj+Ra5Ek9Rl3autjQ8t1SW5lxP/5z2uzJsl3tu0zgH8E/CmwB9jaDtsKPNi29wBb2pNYFwMbgMfa9NdbSa5qT2vdMK/N3LmuAx7x/ogkLa1xn9r6p0PbR4AXGNzoXsiFwK4kqxgE1u6q+oMkjwK7k2wDXgSuB6iqA0l2A0+3n3FTe2IL4EbgbuAMBjfZH2r1u4B724351xk89SVJWkLjPrX1Uyd64qr6CvD9I+pfBTYdp80OYMeI+gzwnvsrVfUOLYgkSdMx7tTWuiSfT3IoyatJPpdk3fu3lCR9sxv3ZvtnGdyP+C4Gj9z+fqtJkla4cYNkTVV9tqqOtOVuwOdoJUljB8lrST7evmC4KsnHga9OsmOSpOVh3CD5V8CPAf8XeIXBo7YnfANekvTNZ9zHf/8dsLWq3oDBG3yBTzAIGEnSCjbuiOSDcyECUFWvM+LRXknSyjNukHzLvL8bcg7jj2YkSd/Exg2D/wD8cZIHGLwa5ccY8cVBSdLKM+432+9JMsPgRY0BPlZVT0+0Z5KkZWHs6akWHIaHJOkYJ/UaeUmS5hgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqMrEgSXJRkj9M8kySA0l+ptXPSfJwkufaevhvwd+SZDbJs0muHqpfkWR/23d7krT6aUnub/V9SdZP6nokSaNNckRyBPi3VfV3gauAm5JcCtwM7K2qDcDe9pm2bwtwGbAZuCPJqnauO4HtwIa2bG71bcAbVXUJ8EngtglejyRphIkFSVW9UlX/q22/BTwDrAWuAXa1w3YB17bta4D7qurdqnoemAWuTHIhcGZVPVpVBdwzr83cuR4ANs2NViRJS2NJ7pG0KafvB/YBF1TVKzAIG+D8dtha4KWhZgdbbW3bnl8/pk1VHQHeBM4d8fO3J5lJMnP48OFFuipJEixBkCT5duBzwM9W1dcWOnRErRaoL9Tm2ELVzqraWFUb16xZ835dliSdgIkGSZIPMAiR366q/9LKr7bpKtr6UKsfBC4aar4OeLnV142oH9MmyWrgLOD1xb8SSdLxTPKprQB3Ac9U1X8c2rUH2Nq2twIPDtW3tCexLmZwU/2xNv31VpKr2jlvmNdm7lzXAY+0+yiSpCWyeoLn/jDwk8D+JE+22i8CtwK7k2wDXgSuB6iqA0l2A08zeOLrpqo62trdCNwNnAE81BYYBNW9SWYZjES2TPB6JEkjTCxIqurLjL6HAbDpOG12ADtG1GeAy0fU36EFkSRpOvxmuySpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSukwsSJJ8JsmhJE8N1c5J8nCS59r67KF9tySZTfJskquH6lck2d/23Z4krX5akvtbfV+S9ZO6FknS8U1yRHI3sHle7WZgb1VtAPa2zyS5FNgCXNba3JFkVWtzJ7Ad2NCWuXNuA96oqkuATwK3TexKJEnHNbEgqaovAa/PK18D7Grbu4Brh+r3VdW7VfU8MAtcmeRC4MyqerSqCrhnXpu5cz0AbJobrUiSls5S3yO5oKpeAWjr81t9LfDS0HEHW21t255fP6ZNVR0B3gTOnVjPJUkjnSo320eNJGqB+kJt3nvyZHuSmSQzhw8fPskuSpJGWeogebVNV9HWh1r9IHDR0HHrgJdbfd2I+jFtkqwGzuK9U2kAVNXOqtpYVRvXrFmzSJciSYKlD5I9wNa2vRV4cKi+pT2JdTGDm+qPtemvt5Jc1e5/3DCvzdy5rgMeafdRJElLaPWkTpzkd4GPAOclOQj8MnArsDvJNuBF4HqAqjqQZDfwNHAEuKmqjrZT3cjgCbAzgIfaAnAXcG+SWQYjkS2TuhZJ0vFNLEiq6sePs2vTcY7fAewYUZ8BLh9Rf4cWRJKk6TlVbrZLkpYpg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXVZPuwOSFs+Lv/a90+6CTkF/65f2T/T8jkgkSV0MEklSF4NEktRl2QdJks1Jnk0ym+TmafdHklaaZR0kSVYBvwn8E+BS4MeTXDrdXknSyrKsgwS4Epitqj+rqr8E7gOumXKfJGlFWe6P/64FXhr6fBD4gfkHJdkObG8f307y7BL0baU4D3ht2p04FeQTW6fdBR3L3805v5zFOMt3H2/Hcg+SUf869Z5C1U5g5+S7s/IkmamqjdPuhzSfv5tLZ7lPbR0ELhr6vA54eUp9kaQVabkHyePAhiQXJ/kbwBZgz5T7JEkryrKe2qqqI0n+DfAFYBXwmao6MOVurTROGepU5e/mEknVe24pSJI0tuU+tSVJmjKDRJLUxSDRSfHVNDpVJflMkkNJnpp2X1YKg0QnzFfT6BR3N7B52p1YSQwSnQxfTaNTVlV9CXh92v1YSQwSnYxRr6ZZO6W+SJoyg0QnY6xX00haGQwSnQxfTSPp6wwSnQxfTSPp6wwSnbCqOgLMvZrmGWC3r6bRqSLJ7wKPAn8nycEk26bdp292viJFktTFEYkkqYtBIknqYpBIkroYJJKkLgaJJKmLQSItgiR//D77X0iyP8mTbfnBCfThi0k2LvZ5pfezrP/UrnSqqKpxguGHq+q1UTuSrKqqo4vcLWlJOCKRFkGSt9v6wiRfaqOOp5L8w4XaJPm1JPuAf5Dkl5I83trtTJJ23NdHGknOS/JC2z4jyX1JvpLkfuCMiV+oNIJBIi2unwC+UFUfAr4PeHJo3x+2gNnXPn8b8FRV/UBVfRn4VFX9/aq6nEEo/Oj7/Kwbgf9XVR8EdgBXLOJ1SGNzaktaXI8Dn0nyAeD3qurJoX3zp7aOAp8b3p/k54FvBc4BDgC/v8DP+iHgdoCq+kqSryxC/6UT5ohEWkTtjyr9EPDnwL1Jbljg8Hfm7oskOR24A7iuqr4X+DRwejvuCN/4b/X0eefwHUeaOoNEWkRJvhs4VFWfBu4C/t6YTecC4rUk3w5cN7TvBb4xbTVc/xLwL9vPvRz44El2W+ri1Ja0uD4C/FySvwLeBhYakXxdVf1Fkk8D+xkEx+NDuz8B7E7yk8AjQ/U7gc+2Ka0ngcd6Oy+dDN/+K0nq4tSWJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuvx/HFrpXswqmGoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Taking a look at the target variable\n",
    "#normal transaction = 0\n",
    "#fraudulent transaction = 1\n",
    "print(fraud_data.isFraud.value_counts())\n",
    "print(fraud_data.isFraud.value_counts(normalize=True) * 100)\n",
    "\n",
    "# visualize the target variable column\n",
    "sns.countplot(fraud_data.isFraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the results - 3.40% of transactions are fraudulent and 99.60% of transactions are normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransactionID      0.000000\n",
      "isFraud            0.000000\n",
      "TransactionDT      0.000000\n",
      "TransactionAmt     0.000000\n",
      "ProductCD          0.000000\n",
      "card1              0.000000\n",
      "card2              1.549429\n",
      "card3              0.267552\n",
      "card4              0.274325\n",
      "card5              0.751854\n",
      "card6              0.269245\n",
      "addr1             11.392962\n",
      "addr2             11.392962\n",
      "dist1             59.865547\n",
      "dist2             93.443289\n",
      "P_emaildomain     15.934568\n",
      "R_emaildomain     76.572290\n",
      "C1                 0.000000\n",
      "C2                 0.000000\n",
      "C3                 0.000000\n",
      "C4                 0.000000\n",
      "C5                 0.000000\n",
      "C6                 0.000000\n",
      "C7                 0.000000\n",
      "C8                 0.000000\n",
      "C9                 0.000000\n",
      "C10                0.000000\n",
      "C11                0.000000\n",
      "C12                0.000000\n",
      "C13                0.000000\n",
      "C14                0.000000\n",
      "D1                 0.204897\n",
      "D2                47.336336\n",
      "D3                44.391574\n",
      "D4                28.526433\n",
      "D5                52.458767\n",
      "D6                87.433535\n",
      "D7                93.316287\n",
      "D8                87.210011\n",
      "D9                87.210011\n",
      "D10               12.767975\n",
      "D11               47.671623\n",
      "D12               88.857656\n",
      "D13               89.291157\n",
      "D14               89.303011\n",
      "D15               15.189488\n",
      "M1                46.261049\n",
      "M2                46.261049\n",
      "M3                46.261049\n",
      "M4                47.427778\n",
      "M5                59.340604\n",
      "M6                28.946388\n",
      "M7                58.896942\n",
      "M8                58.893555\n",
      "M9                58.893555\n",
      "V1                47.671623\n",
      "V2                47.671623\n",
      "V3                47.671623\n",
      "V4                47.671623\n",
      "V5                47.671623\n",
      "V6                47.671623\n",
      "V7                47.671623\n",
      "V8                47.671623\n",
      "V9                47.671623\n",
      "V10               47.671623\n",
      "V11               47.671623\n",
      "V12               12.776442\n",
      "V13               12.776442\n",
      "V14               12.776442\n",
      "V15               12.776442\n",
      "V16               12.776442\n",
      "V17               12.776442\n",
      "V18               12.776442\n",
      "V19               12.776442\n",
      "V20               12.776442\n",
      "V21               12.776442\n",
      "V22               12.776442\n",
      "V23               12.776442\n",
      "V24               12.776442\n",
      "V25               12.776442\n",
      "V26               12.776442\n",
      "V27               12.776442\n",
      "V28               12.776442\n",
      "V29               12.776442\n",
      "V30               12.776442\n",
      "V31               12.776442\n",
      "V32               12.776442\n",
      "V33               12.776442\n",
      "V34               12.776442\n",
      "V35               28.536594\n",
      "V36               28.536594\n",
      "V37               28.536594\n",
      "V38               28.536594\n",
      "V39               28.536594\n",
      "V40               28.536594\n",
      "V41               28.536594\n",
      "V42               28.536594\n",
      "V43               28.536594\n",
      "V44               28.536594\n",
      "V45               28.536594\n",
      "V46               28.536594\n",
      "V47               28.536594\n",
      "V48               28.536594\n",
      "V49               28.536594\n",
      "V50               28.536594\n",
      "V51               28.536594\n",
      "V52               28.536594\n",
      "V53               13.006740\n",
      "V54               13.006740\n",
      "V55               13.006740\n",
      "V56               13.006740\n",
      "V57               13.006740\n",
      "V58               13.006740\n",
      "V59               13.006740\n",
      "V60               13.006740\n",
      "V61               13.006740\n",
      "V62               13.006740\n",
      "V63               13.006740\n",
      "V64               13.006740\n",
      "V65               13.006740\n",
      "V66               13.006740\n",
      "V67               13.006740\n",
      "V68               13.006740\n",
      "V69               13.006740\n",
      "V70               13.006740\n",
      "V71               13.006740\n",
      "V72               13.006740\n",
      "V73               13.006740\n",
      "V74               13.006740\n",
      "V75               15.197954\n",
      "V76               15.197954\n",
      "V77               15.197954\n",
      "V78               15.197954\n",
      "V79               15.197954\n",
      "V80               15.197954\n",
      "V81               15.197954\n",
      "V82               15.197954\n",
      "V83               15.197954\n",
      "V84               15.197954\n",
      "V85               15.197954\n",
      "V86               15.197954\n",
      "V87               15.197954\n",
      "V88               15.197954\n",
      "V89               15.197954\n",
      "V90               15.197954\n",
      "V91               15.197954\n",
      "V92               15.197954\n",
      "V93               15.197954\n",
      "V94               15.197954\n",
      "V95                0.057574\n",
      "V96                0.057574\n",
      "V97                0.057574\n",
      "V98                0.057574\n",
      "V99                0.057574\n",
      "V100               0.057574\n",
      "V101               0.057574\n",
      "V102               0.057574\n",
      "V103               0.057574\n",
      "V104               0.057574\n",
      "V105               0.057574\n",
      "V106               0.057574\n",
      "V107               0.057574\n",
      "V108               0.057574\n",
      "V109               0.057574\n",
      "V110               0.057574\n",
      "V111               0.057574\n",
      "V112               0.057574\n",
      "V113               0.057574\n",
      "V114               0.057574\n",
      "V115               0.057574\n",
      "V116               0.057574\n",
      "V117               0.057574\n",
      "V118               0.057574\n",
      "V119               0.057574\n",
      "V120               0.057574\n",
      "V121               0.057574\n",
      "V122               0.057574\n",
      "V123               0.057574\n",
      "V124               0.057574\n",
      "V125               0.057574\n",
      "V126               0.057574\n",
      "V127               0.057574\n",
      "V128               0.057574\n",
      "V129               0.057574\n",
      "V130               0.057574\n",
      "V131               0.057574\n",
      "V132               0.057574\n",
      "V133               0.057574\n",
      "V134               0.057574\n",
      "V135               0.057574\n",
      "V136               0.057574\n",
      "V137               0.057574\n",
      "V138              86.171978\n",
      "V139              86.171978\n",
      "V140              86.171978\n",
      "V141              86.171978\n",
      "V142              86.171978\n",
      "V143              86.171978\n",
      "V144              86.171978\n",
      "V145              86.171978\n",
      "V146              86.171978\n",
      "V147              86.171978\n",
      "V148              86.171978\n",
      "V149              86.171978\n",
      "V150              86.171978\n",
      "V151              86.171978\n",
      "V152              86.171978\n",
      "V153              86.171978\n",
      "V154              86.171978\n",
      "V155              86.171978\n",
      "V156              86.171978\n",
      "V157              86.171978\n",
      "V158              86.171978\n",
      "V159              86.171978\n",
      "V160              86.171978\n",
      "V161              86.171978\n",
      "V162              86.171978\n",
      "V163              86.171978\n",
      "V164              86.171978\n",
      "V165              86.171978\n",
      "V166              86.171978\n",
      "V167              76.196363\n",
      "V168              76.196363\n",
      "V169              76.170962\n",
      "V170              76.170962\n",
      "V171              76.170962\n",
      "V172              76.196363\n",
      "V173              76.196363\n",
      "V174              76.170962\n",
      "V175              76.170962\n",
      "V176              76.196363\n",
      "V177              76.196363\n",
      "V178              76.196363\n",
      "V179              76.196363\n",
      "V180              76.170962\n",
      "V181              76.196363\n",
      "V182              76.196363\n",
      "V183              76.196363\n",
      "V184              76.170962\n",
      "V185              76.170962\n",
      "V186              76.196363\n",
      "V187              76.196363\n",
      "V188              76.170962\n",
      "V189              76.170962\n",
      "V190              76.196363\n",
      "V191              76.196363\n",
      "V192              76.196363\n",
      "V193              76.196363\n",
      "V194              76.170962\n",
      "V195              76.170962\n",
      "V196              76.196363\n",
      "V197              76.170962\n",
      "V198              76.170962\n",
      "V199              76.196363\n",
      "V200              76.170962\n",
      "V201              76.170962\n",
      "V202              76.196363\n",
      "V203              76.196363\n",
      "V204              76.196363\n",
      "V205              76.196363\n",
      "V206              76.196363\n",
      "V207              76.196363\n",
      "V208              76.170962\n",
      "V209              76.170962\n",
      "V210              76.170962\n",
      "V211              76.196363\n",
      "V212              76.196363\n",
      "V213              76.196363\n",
      "V214              76.196363\n",
      "V215              76.196363\n",
      "V216              76.196363\n",
      "V217              77.842314\n",
      "V218              77.842314\n",
      "V219              77.842314\n",
      "V220              75.869543\n",
      "V221              75.869543\n",
      "V222              75.869543\n",
      "V223              77.842314\n",
      "V224              77.842314\n",
      "V225              77.842314\n",
      "V226              77.842314\n",
      "V227              75.869543\n",
      "V228              77.842314\n",
      "V229              77.842314\n",
      "V230              77.842314\n",
      "V231              77.842314\n",
      "V232              77.842314\n",
      "V233              77.842314\n",
      "V234              75.869543\n",
      "V235              77.842314\n",
      "V236              77.842314\n",
      "V237              77.842314\n",
      "V238              75.869543\n",
      "V239              75.869543\n",
      "V240              77.842314\n",
      "V241              77.842314\n",
      "V242              77.842314\n",
      "V243              77.842314\n",
      "V244              77.842314\n",
      "V245              75.869543\n",
      "V246              77.842314\n",
      "V247              77.842314\n",
      "V248              77.842314\n",
      "V249              77.842314\n",
      "V250              75.869543\n",
      "V251              75.869543\n",
      "V252              77.842314\n",
      "V253              77.842314\n",
      "V254              77.842314\n",
      "V255              75.869543\n",
      "V256              75.869543\n",
      "V257              77.842314\n",
      "V258              77.842314\n",
      "V259              75.869543\n",
      "V260              77.842314\n",
      "V261              77.842314\n",
      "V262              77.842314\n",
      "V263              77.842314\n",
      "V264              77.842314\n",
      "V265              77.842314\n",
      "V266              77.842314\n",
      "V267              77.842314\n",
      "V268              77.842314\n",
      "V269              77.842314\n",
      "V270              75.869543\n",
      "V271              75.869543\n",
      "V272              75.869543\n",
      "V273              77.842314\n",
      "V274              77.842314\n",
      "V275              77.842314\n",
      "V276              77.842314\n",
      "V277              77.842314\n",
      "V278              77.842314\n",
      "V279               0.005080\n",
      "V280               0.005080\n",
      "V281               0.204897\n",
      "V282               0.204897\n",
      "V283               0.204897\n",
      "V284               0.005080\n",
      "V285               0.005080\n",
      "V286               0.005080\n",
      "V287               0.005080\n",
      "V288               0.204897\n",
      "V289               0.204897\n",
      "V290               0.005080\n",
      "V291               0.005080\n",
      "V292               0.005080\n",
      "V293               0.005080\n",
      "V294               0.005080\n",
      "V295               0.005080\n",
      "V296               0.204897\n",
      "V297               0.005080\n",
      "V298               0.005080\n",
      "V299               0.005080\n",
      "V300               0.204897\n",
      "V301               0.204897\n",
      "V302               0.005080\n",
      "V303               0.005080\n",
      "V304               0.005080\n",
      "V305               0.005080\n",
      "V306               0.005080\n",
      "V307               0.005080\n",
      "V308               0.005080\n",
      "V309               0.005080\n",
      "V310               0.005080\n",
      "V311               0.005080\n",
      "V312               0.005080\n",
      "V313               0.204897\n",
      "V314               0.204897\n",
      "V315               0.204897\n",
      "V316               0.005080\n",
      "V317               0.005080\n",
      "V318               0.005080\n",
      "V319               0.005080\n",
      "V320               0.005080\n",
      "V321               0.005080\n",
      "V322              86.095777\n",
      "V323              86.095777\n",
      "V324              86.095777\n",
      "V325              86.095777\n",
      "V326              86.095777\n",
      "V327              86.095777\n",
      "V328              86.095777\n",
      "V329              86.095777\n",
      "V330              86.095777\n",
      "V331              86.095777\n",
      "V332              86.095777\n",
      "V333              86.095777\n",
      "V334              86.095777\n",
      "V335              86.095777\n",
      "V336              86.095777\n",
      "V337              86.095777\n",
      "V338              86.095777\n",
      "V339              86.095777\n",
      "id_01             75.353067\n",
      "id_02             75.964372\n",
      "id_03             88.659532\n",
      "id_04             88.659532\n",
      "id_05             76.597690\n",
      "id_06             76.597690\n",
      "id_07             99.110983\n",
      "id_08             99.110983\n",
      "id_09             87.210011\n",
      "id_10             87.210011\n",
      "id_11             75.945745\n",
      "id_12             75.353067\n",
      "id_13             78.177600\n",
      "id_14             86.515731\n",
      "id_15             75.945745\n",
      "id_16             77.967623\n",
      "id_17             76.189589\n",
      "id_18             92.361229\n",
      "id_19             76.192976\n",
      "id_20             76.201443\n",
      "id_21             99.110983\n",
      "id_22             99.110983\n",
      "id_23             99.110983\n",
      "id_24             99.175331\n",
      "id_25             99.112677\n",
      "id_26             99.110983\n",
      "id_27             99.110983\n",
      "id_28             75.945745\n",
      "id_29             75.945745\n",
      "id_30             86.937379\n",
      "id_31             76.065974\n",
      "id_32             86.935686\n",
      "id_33             87.636739\n",
      "id_34             86.891658\n",
      "id_35             75.945745\n",
      "id_36             75.945745\n",
      "id_37             75.945745\n",
      "id_38             75.945745\n",
      "DeviceType        75.979612\n",
      "DeviceInfo        79.813391\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Missing values - To get percentage of missing data in each column\n",
    "print(fraud_data.isnull().sum() / len(fraud_data) * 100 ) \n",
    "\n",
    "# getting all the numerical columns\n",
    "num_cols = fraud_data.select_dtypes(include=np.number).columns \n",
    "# filling missing values of numerical columns with mean value\n",
    "fraud_data[num_cols] = fraud_data[num_cols].fillna(fraud_data[num_cols].mean())   # fills the missing values with mean\n",
    "\n",
    "# getting all the categorical columns\n",
    "cat_cols = fraud_data.select_dtypes(include = 'object').columns    \n",
    "\n",
    "# fills the missing values with maximum occuring element in the column\n",
    "fraud_data[cat_cols] = fraud_data[cat_cols].fillna(fraud_data[cat_cols].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID     0.0\n",
       "isFraud           0.0\n",
       "TransactionDT     0.0\n",
       "TransactionAmt    0.0\n",
       "ProductCD         0.0\n",
       "card1             0.0\n",
       "card2             0.0\n",
       "card3             0.0\n",
       "card4             0.0\n",
       "card5             0.0\n",
       "card6             0.0\n",
       "addr1             0.0\n",
       "addr2             0.0\n",
       "dist1             0.0\n",
       "dist2             0.0\n",
       "P_emaildomain     0.0\n",
       "R_emaildomain     0.0\n",
       "C1                0.0\n",
       "C2                0.0\n",
       "C3                0.0\n",
       "C4                0.0\n",
       "C5                0.0\n",
       "C6                0.0\n",
       "C7                0.0\n",
       "C8                0.0\n",
       "C9                0.0\n",
       "C10               0.0\n",
       "C11               0.0\n",
       "C12               0.0\n",
       "C13               0.0\n",
       "C14               0.0\n",
       "D1                0.0\n",
       "D2                0.0\n",
       "D3                0.0\n",
       "D4                0.0\n",
       "D5                0.0\n",
       "D6                0.0\n",
       "D7                0.0\n",
       "D8                0.0\n",
       "D9                0.0\n",
       "D10               0.0\n",
       "D11               0.0\n",
       "D12               0.0\n",
       "D13               0.0\n",
       "D14               0.0\n",
       "D15               0.0\n",
       "M1                0.0\n",
       "M2                0.0\n",
       "M3                0.0\n",
       "M4                0.0\n",
       "M5                0.0\n",
       "M6                0.0\n",
       "M7                0.0\n",
       "M8                0.0\n",
       "M9                0.0\n",
       "V1                0.0\n",
       "V2                0.0\n",
       "V3                0.0\n",
       "V4                0.0\n",
       "V5                0.0\n",
       "V6                0.0\n",
       "V7                0.0\n",
       "V8                0.0\n",
       "V9                0.0\n",
       "V10               0.0\n",
       "V11               0.0\n",
       "V12               0.0\n",
       "V13               0.0\n",
       "V14               0.0\n",
       "V15               0.0\n",
       "V16               0.0\n",
       "V17               0.0\n",
       "V18               0.0\n",
       "V19               0.0\n",
       "V20               0.0\n",
       "V21               0.0\n",
       "V22               0.0\n",
       "V23               0.0\n",
       "V24               0.0\n",
       "V25               0.0\n",
       "V26               0.0\n",
       "V27               0.0\n",
       "V28               0.0\n",
       "V29               0.0\n",
       "V30               0.0\n",
       "V31               0.0\n",
       "V32               0.0\n",
       "V33               0.0\n",
       "V34               0.0\n",
       "V35               0.0\n",
       "V36               0.0\n",
       "V37               0.0\n",
       "V38               0.0\n",
       "V39               0.0\n",
       "V40               0.0\n",
       "V41               0.0\n",
       "V42               0.0\n",
       "V43               0.0\n",
       "V44               0.0\n",
       "V45               0.0\n",
       "V46               0.0\n",
       "V47               0.0\n",
       "V48               0.0\n",
       "V49               0.0\n",
       "V50               0.0\n",
       "V51               0.0\n",
       "V52               0.0\n",
       "V53               0.0\n",
       "V54               0.0\n",
       "V55               0.0\n",
       "V56               0.0\n",
       "V57               0.0\n",
       "V58               0.0\n",
       "V59               0.0\n",
       "V60               0.0\n",
       "V61               0.0\n",
       "V62               0.0\n",
       "V63               0.0\n",
       "V64               0.0\n",
       "V65               0.0\n",
       "V66               0.0\n",
       "V67               0.0\n",
       "V68               0.0\n",
       "V69               0.0\n",
       "V70               0.0\n",
       "V71               0.0\n",
       "V72               0.0\n",
       "V73               0.0\n",
       "V74               0.0\n",
       "V75               0.0\n",
       "V76               0.0\n",
       "V77               0.0\n",
       "V78               0.0\n",
       "V79               0.0\n",
       "V80               0.0\n",
       "V81               0.0\n",
       "V82               0.0\n",
       "V83               0.0\n",
       "V84               0.0\n",
       "V85               0.0\n",
       "V86               0.0\n",
       "V87               0.0\n",
       "V88               0.0\n",
       "V89               0.0\n",
       "V90               0.0\n",
       "V91               0.0\n",
       "V92               0.0\n",
       "V93               0.0\n",
       "V94               0.0\n",
       "V95               0.0\n",
       "V96               0.0\n",
       "V97               0.0\n",
       "V98               0.0\n",
       "V99               0.0\n",
       "V100              0.0\n",
       "V101              0.0\n",
       "V102              0.0\n",
       "V103              0.0\n",
       "V104              0.0\n",
       "V105              0.0\n",
       "V106              0.0\n",
       "V107              0.0\n",
       "V108              0.0\n",
       "V109              0.0\n",
       "V110              0.0\n",
       "V111              0.0\n",
       "V112              0.0\n",
       "V113              0.0\n",
       "V114              0.0\n",
       "V115              0.0\n",
       "V116              0.0\n",
       "V117              0.0\n",
       "V118              0.0\n",
       "V119              0.0\n",
       "V120              0.0\n",
       "V121              0.0\n",
       "V122              0.0\n",
       "V123              0.0\n",
       "V124              0.0\n",
       "V125              0.0\n",
       "V126              0.0\n",
       "V127              0.0\n",
       "V128              0.0\n",
       "V129              0.0\n",
       "V130              0.0\n",
       "V131              0.0\n",
       "V132              0.0\n",
       "V133              0.0\n",
       "V134              0.0\n",
       "V135              0.0\n",
       "V136              0.0\n",
       "V137              0.0\n",
       "V138              0.0\n",
       "V139              0.0\n",
       "V140              0.0\n",
       "V141              0.0\n",
       "V142              0.0\n",
       "V143              0.0\n",
       "V144              0.0\n",
       "V145              0.0\n",
       "V146              0.0\n",
       "V147              0.0\n",
       "V148              0.0\n",
       "V149              0.0\n",
       "V150              0.0\n",
       "V151              0.0\n",
       "V152              0.0\n",
       "V153              0.0\n",
       "V154              0.0\n",
       "V155              0.0\n",
       "V156              0.0\n",
       "V157              0.0\n",
       "V158              0.0\n",
       "V159              0.0\n",
       "V160              0.0\n",
       "V161              0.0\n",
       "V162              0.0\n",
       "V163              0.0\n",
       "V164              0.0\n",
       "V165              0.0\n",
       "V166              0.0\n",
       "V167              0.0\n",
       "V168              0.0\n",
       "V169              0.0\n",
       "V170              0.0\n",
       "V171              0.0\n",
       "V172              0.0\n",
       "V173              0.0\n",
       "V174              0.0\n",
       "V175              0.0\n",
       "V176              0.0\n",
       "V177              0.0\n",
       "V178              0.0\n",
       "V179              0.0\n",
       "V180              0.0\n",
       "V181              0.0\n",
       "V182              0.0\n",
       "V183              0.0\n",
       "V184              0.0\n",
       "V185              0.0\n",
       "V186              0.0\n",
       "V187              0.0\n",
       "V188              0.0\n",
       "V189              0.0\n",
       "V190              0.0\n",
       "V191              0.0\n",
       "V192              0.0\n",
       "V193              0.0\n",
       "V194              0.0\n",
       "V195              0.0\n",
       "V196              0.0\n",
       "V197              0.0\n",
       "V198              0.0\n",
       "V199              0.0\n",
       "V200              0.0\n",
       "V201              0.0\n",
       "V202              0.0\n",
       "V203              0.0\n",
       "V204              0.0\n",
       "V205              0.0\n",
       "V206              0.0\n",
       "V207              0.0\n",
       "V208              0.0\n",
       "V209              0.0\n",
       "V210              0.0\n",
       "V211              0.0\n",
       "V212              0.0\n",
       "V213              0.0\n",
       "V214              0.0\n",
       "V215              0.0\n",
       "V216              0.0\n",
       "V217              0.0\n",
       "V218              0.0\n",
       "V219              0.0\n",
       "V220              0.0\n",
       "V221              0.0\n",
       "V222              0.0\n",
       "V223              0.0\n",
       "V224              0.0\n",
       "V225              0.0\n",
       "V226              0.0\n",
       "V227              0.0\n",
       "V228              0.0\n",
       "V229              0.0\n",
       "V230              0.0\n",
       "V231              0.0\n",
       "V232              0.0\n",
       "V233              0.0\n",
       "V234              0.0\n",
       "V235              0.0\n",
       "V236              0.0\n",
       "V237              0.0\n",
       "V238              0.0\n",
       "V239              0.0\n",
       "V240              0.0\n",
       "V241              0.0\n",
       "V242              0.0\n",
       "V243              0.0\n",
       "V244              0.0\n",
       "V245              0.0\n",
       "V246              0.0\n",
       "V247              0.0\n",
       "V248              0.0\n",
       "V249              0.0\n",
       "V250              0.0\n",
       "V251              0.0\n",
       "V252              0.0\n",
       "V253              0.0\n",
       "V254              0.0\n",
       "V255              0.0\n",
       "V256              0.0\n",
       "V257              0.0\n",
       "V258              0.0\n",
       "V259              0.0\n",
       "V260              0.0\n",
       "V261              0.0\n",
       "V262              0.0\n",
       "V263              0.0\n",
       "V264              0.0\n",
       "V265              0.0\n",
       "V266              0.0\n",
       "V267              0.0\n",
       "V268              0.0\n",
       "V269              0.0\n",
       "V270              0.0\n",
       "V271              0.0\n",
       "V272              0.0\n",
       "V273              0.0\n",
       "V274              0.0\n",
       "V275              0.0\n",
       "V276              0.0\n",
       "V277              0.0\n",
       "V278              0.0\n",
       "V279              0.0\n",
       "V280              0.0\n",
       "V281              0.0\n",
       "V282              0.0\n",
       "V283              0.0\n",
       "V284              0.0\n",
       "V285              0.0\n",
       "V286              0.0\n",
       "V287              0.0\n",
       "V288              0.0\n",
       "V289              0.0\n",
       "V290              0.0\n",
       "V291              0.0\n",
       "V292              0.0\n",
       "V293              0.0\n",
       "V294              0.0\n",
       "V295              0.0\n",
       "V296              0.0\n",
       "V297              0.0\n",
       "V298              0.0\n",
       "V299              0.0\n",
       "V300              0.0\n",
       "V301              0.0\n",
       "V302              0.0\n",
       "V303              0.0\n",
       "V304              0.0\n",
       "V305              0.0\n",
       "V306              0.0\n",
       "V307              0.0\n",
       "V308              0.0\n",
       "V309              0.0\n",
       "V310              0.0\n",
       "V311              0.0\n",
       "V312              0.0\n",
       "V313              0.0\n",
       "V314              0.0\n",
       "V315              0.0\n",
       "V316              0.0\n",
       "V317              0.0\n",
       "V318              0.0\n",
       "V319              0.0\n",
       "V320              0.0\n",
       "V321              0.0\n",
       "V322              0.0\n",
       "V323              0.0\n",
       "V324              0.0\n",
       "V325              0.0\n",
       "V326              0.0\n",
       "V327              0.0\n",
       "V328              0.0\n",
       "V329              0.0\n",
       "V330              0.0\n",
       "V331              0.0\n",
       "V332              0.0\n",
       "V333              0.0\n",
       "V334              0.0\n",
       "V335              0.0\n",
       "V336              0.0\n",
       "V337              0.0\n",
       "V338              0.0\n",
       "V339              0.0\n",
       "id_01             0.0\n",
       "id_02             0.0\n",
       "id_03             0.0\n",
       "id_04             0.0\n",
       "id_05             0.0\n",
       "id_06             0.0\n",
       "id_07             0.0\n",
       "id_08             0.0\n",
       "id_09             0.0\n",
       "id_10             0.0\n",
       "id_11             0.0\n",
       "id_12             0.0\n",
       "id_13             0.0\n",
       "id_14             0.0\n",
       "id_15             0.0\n",
       "id_16             0.0\n",
       "id_17             0.0\n",
       "id_18             0.0\n",
       "id_19             0.0\n",
       "id_20             0.0\n",
       "id_21             0.0\n",
       "id_22             0.0\n",
       "id_23             0.0\n",
       "id_24             0.0\n",
       "id_25             0.0\n",
       "id_26             0.0\n",
       "id_27             0.0\n",
       "id_28             0.0\n",
       "id_29             0.0\n",
       "id_30             0.0\n",
       "id_31             0.0\n",
       "id_32             0.0\n",
       "id_33             0.0\n",
       "id_34             0.0\n",
       "id_35             0.0\n",
       "id_36             0.0\n",
       "id_37             0.0\n",
       "id_38             0.0\n",
       "DeviceType        0.0\n",
       "DeviceInfo        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look if there still exist any missing values\n",
    "fraud_data.isnull().sum() / len(fraud_data) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding\n",
    "Machine learning models require all input and output variables to be numeric. Run the model with data as-is and then iterate for feature engineering. This means that if your data contains categorical data, you must encode it to numbers before you can fit and evaluate a model.\n",
    "\n",
    "Ordinal encoding - The integer values have a natural ordered relationship between each other and machine learning algorithms may be able to understand and harness this relationship.\n",
    "\n",
    "For categorical variables where no ordinal relationship exists, the integer encoding may not be enough, at best, or misleading to the model at worst. In this case, a one-hot encoding can be applied to the ordinal representation.\n",
    "\n",
    "The one-hot encoding creates one binary variable for each category. The problem is that this representation includes redundancy. For example, if we know that [1, 0, 0] represents â€œblueâ€ and [0, 1, 0] represents â€œgreenâ€ we donâ€™t need another binary variable to represent â€œredâ€œ, instead we could use 0 values for both â€œblueâ€ and â€œgreenâ€ alone, e.g.. [0, 0].\n",
    "\n",
    "This is called a dummy variable encoding, and always represents C categories with C-1 binary variables. In addition to being slightly less redundant, a dummy variable representation is required for some models.\n",
    "\n",
    "For example, in the case of a linear regression model (and other regression models that have a bias term), a one hot encoding will case the matrix of input data to become singular, meaning it cannot be inverted and the linear regression coefficients cannot be calculated using linear algebra. For these types of models a dummy variable encoding must be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59054, 434)\n",
      "(59054, 1667)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceInfo_rv:54.0</th>\n",
       "      <th>DeviceInfo_rv:55.0</th>\n",
       "      <th>DeviceInfo_rv:56.0</th>\n",
       "      <th>DeviceInfo_rv:57.0</th>\n",
       "      <th>DeviceInfo_rv:58.0</th>\n",
       "      <th>DeviceInfo_rv:59.0</th>\n",
       "      <th>DeviceInfo_rv:60.0</th>\n",
       "      <th>DeviceInfo_verykools4009</th>\n",
       "      <th>DeviceInfo_verykools5034</th>\n",
       "      <th>DeviceInfo_vivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2994681</td>\n",
       "      <td>0</td>\n",
       "      <td>242834</td>\n",
       "      <td>25.000</td>\n",
       "      <td>9803</td>\n",
       "      <td>583.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3557242</td>\n",
       "      <td>0</td>\n",
       "      <td>15123000</td>\n",
       "      <td>117.000</td>\n",
       "      <td>7919</td>\n",
       "      <td>194.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3327470</td>\n",
       "      <td>0</td>\n",
       "      <td>8378575</td>\n",
       "      <td>73.773</td>\n",
       "      <td>12778</td>\n",
       "      <td>500.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3118781</td>\n",
       "      <td>0</td>\n",
       "      <td>2607840</td>\n",
       "      <td>400.000</td>\n",
       "      <td>12316</td>\n",
       "      <td>548.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3459772</td>\n",
       "      <td>0</td>\n",
       "      <td>12226544</td>\n",
       "      <td>31.950</td>\n",
       "      <td>9002</td>\n",
       "      <td>453.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1667 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt  card1  card2  card3  \\\n",
       "0        2994681        0         242834          25.000   9803  583.0  150.0   \n",
       "1        3557242        0       15123000         117.000   7919  194.0  150.0   \n",
       "2        3327470        0        8378575          73.773  12778  500.0  185.0   \n",
       "3        3118781        0        2607840         400.000  12316  548.0  150.0   \n",
       "4        3459772        0       12226544          31.950   9002  453.0  150.0   \n",
       "\n",
       "   card5  addr1  addr2  ...  DeviceInfo_rv:54.0  DeviceInfo_rv:55.0  \\\n",
       "0  226.0  269.0   87.0  ...                   0                   0   \n",
       "1  166.0  181.0   87.0  ...                   0                   0   \n",
       "2  224.0  284.0   60.0  ...                   0                   0   \n",
       "3  195.0  441.0   87.0  ...                   0                   0   \n",
       "4  226.0  264.0   87.0  ...                   0                   0   \n",
       "\n",
       "   DeviceInfo_rv:56.0  DeviceInfo_rv:57.0  DeviceInfo_rv:58.0  \\\n",
       "0                   1                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   DeviceInfo_rv:59.0  DeviceInfo_rv:60.0  DeviceInfo_verykools4009  \\\n",
       "0                   0                   0                         0   \n",
       "1                   0                   0                         0   \n",
       "2                   0                   0                         0   \n",
       "3                   0                   0                         0   \n",
       "4                   0                   0                         0   \n",
       "\n",
       "   DeviceInfo_verykools5034  DeviceInfo_vivo  \n",
       "0                         0                0  \n",
       "1                         0                0  \n",
       "2                         0                0  \n",
       "3                         0                0  \n",
       "4                         0                0  \n",
       "\n",
       "[5 rows x 1667 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# earlier we have collected all the categorical columns in cat_cols\n",
    "print(fraud_data.shape)\n",
    "fraud_data[cat_cols] = fraud_data[cat_cols].fillna(fraud_data[cat_cols].mode().iloc[0])\n",
    "fraud_data = pd.get_dummies(fraud_data, columns=cat_cols)\n",
    "print(fraud_data.shape)\n",
    "fraud_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature transformation\n",
    "In most cases, the numerical features of the dataset do not have a certain range and they differ from each other. In real life, it is nonsense to expect age and income columns to have the same range. But from the machine learning point of view, how these two columns can be compared? Scaling solves this problem.\n",
    "\n",
    "The continuous features become identical in terms of the range, after a scaling process. This process is not mandatory for many algorithms, but it might be still nice to apply. However, the algorithms based on distance calculations such as k-NN or k-Means need to have scaled continuous features as model input.\n",
    "\n",
    "Normalization (or min-max normalization) scale all values in a fixed range between 0 and 1. This transformation does not change the distribution of the feature and due to the decreased standard deviations, the effects of the outliers increases. Therefore, before normalization, it is recommended to handle the outliers.\n",
    "\n",
    "Standardization (or z-score normalization) scales the values while taking into account standard deviation. If the standard deviation of features is different, their range also would differ from each other. This reduces the effect of the outliers in the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input features and output feature\n",
    "# input features\n",
    "X = fraud_data.drop(columns = ['isFraud'])       \n",
    "\n",
    "# output feature\n",
    "Y = fraud_data.isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>dist1</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceInfo_rv:54.0</th>\n",
       "      <th>DeviceInfo_rv:55.0</th>\n",
       "      <th>DeviceInfo_rv:56.0</th>\n",
       "      <th>DeviceInfo_rv:57.0</th>\n",
       "      <th>DeviceInfo_rv:58.0</th>\n",
       "      <th>DeviceInfo_rv:59.0</th>\n",
       "      <th>DeviceInfo_rv:60.0</th>\n",
       "      <th>DeviceInfo_verykools4009</th>\n",
       "      <th>DeviceInfo_verykools5034</th>\n",
       "      <th>DeviceInfo_vivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.688548</td>\n",
       "      <td>-1.544958</td>\n",
       "      <td>-0.468203</td>\n",
       "      <td>-0.021940</td>\n",
       "      <td>1.412632</td>\n",
       "      <td>-0.286861</td>\n",
       "      <td>0.653753</td>\n",
       "      <td>-0.225982</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>1.224253e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00582</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>67.391508</td>\n",
       "      <td>-0.041185</td>\n",
       "      <td>-0.020164</td>\n",
       "      <td>-0.027306</td>\n",
       "      <td>-0.010888</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>-0.004115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.615662</td>\n",
       "      <td>1.681426</td>\n",
       "      <td>-0.073540</td>\n",
       "      <td>-0.406928</td>\n",
       "      <td>-1.078794</td>\n",
       "      <td>-0.286861</td>\n",
       "      <td>-0.804662</td>\n",
       "      <td>-1.144356</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>1.582320e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00582</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>-0.014839</td>\n",
       "      <td>-0.041185</td>\n",
       "      <td>-0.020164</td>\n",
       "      <td>-0.027306</td>\n",
       "      <td>-0.010888</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>-0.004115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.266093</td>\n",
       "      <td>0.219070</td>\n",
       "      <td>-0.258976</td>\n",
       "      <td>0.585989</td>\n",
       "      <td>0.881042</td>\n",
       "      <td>2.788641</td>\n",
       "      <td>0.605139</td>\n",
       "      <td>-0.069441</td>\n",
       "      <td>-10.788933</td>\n",
       "      <td>1.224253e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00582</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>-0.014839</td>\n",
       "      <td>-0.041185</td>\n",
       "      <td>-0.020164</td>\n",
       "      <td>-0.027306</td>\n",
       "      <td>-0.010888</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>-0.004115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.959645</td>\n",
       "      <td>-1.032167</td>\n",
       "      <td>1.140478</td>\n",
       "      <td>0.491581</td>\n",
       "      <td>1.188468</td>\n",
       "      <td>-0.286861</td>\n",
       "      <td>-0.099761</td>\n",
       "      <td>1.569022</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>1.224253e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00582</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>-0.014839</td>\n",
       "      <td>-0.041185</td>\n",
       "      <td>-0.020164</td>\n",
       "      <td>-0.027306</td>\n",
       "      <td>-0.010888</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>-0.004115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.043171</td>\n",
       "      <td>1.053404</td>\n",
       "      <td>-0.438389</td>\n",
       "      <td>-0.185621</td>\n",
       "      <td>0.580022</td>\n",
       "      <td>-0.286861</td>\n",
       "      <td>0.653753</td>\n",
       "      <td>-0.278162</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>-4.551081e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00582</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>-0.014839</td>\n",
       "      <td>-0.041185</td>\n",
       "      <td>-0.020164</td>\n",
       "      <td>-0.027306</td>\n",
       "      <td>-0.010888</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>-0.004115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1666 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  TransactionDT  TransactionAmt     card1     card2     card3  \\\n",
       "0      -1.688548      -1.544958       -0.468203 -0.021940  1.412632 -0.286861   \n",
       "1       1.615662       1.681426       -0.073540 -0.406928 -1.078794 -0.286861   \n",
       "2       0.266093       0.219070       -0.258976  0.585989  0.881042  2.788641   \n",
       "3      -0.959645      -1.032167        1.140478  0.491581  1.188468 -0.286861   \n",
       "4       1.043171       1.053404       -0.438389 -0.185621  0.580022 -0.286861   \n",
       "\n",
       "      card5     addr1      addr2         dist1  ...  DeviceInfo_rv:54.0  \\\n",
       "0  0.653753 -0.225982   0.077832  1.224253e-16  ...            -0.00582   \n",
       "1 -0.804662 -1.144356   0.077832  1.582320e+00  ...            -0.00582   \n",
       "2  0.605139 -0.069441 -10.788933  1.224253e-16  ...            -0.00582   \n",
       "3 -0.099761  1.569022   0.077832  1.224253e-16  ...            -0.00582   \n",
       "4  0.653753 -0.278162   0.077832 -4.551081e-01  ...            -0.00582   \n",
       "\n",
       "   DeviceInfo_rv:55.0  DeviceInfo_rv:56.0  DeviceInfo_rv:57.0  \\\n",
       "0           -0.004115           67.391508           -0.041185   \n",
       "1           -0.004115           -0.014839           -0.041185   \n",
       "2           -0.004115           -0.014839           -0.041185   \n",
       "3           -0.004115           -0.014839           -0.041185   \n",
       "4           -0.004115           -0.014839           -0.041185   \n",
       "\n",
       "   DeviceInfo_rv:58.0  DeviceInfo_rv:59.0  DeviceInfo_rv:60.0  \\\n",
       "0           -0.020164           -0.027306           -0.010888   \n",
       "1           -0.020164           -0.027306           -0.010888   \n",
       "2           -0.020164           -0.027306           -0.010888   \n",
       "3           -0.020164           -0.027306           -0.010888   \n",
       "4           -0.020164           -0.027306           -0.010888   \n",
       "\n",
       "   DeviceInfo_verykools4009  DeviceInfo_verykools5034  DeviceInfo_vivo  \n",
       "0                 -0.004115                 -0.004115        -0.004115  \n",
       "1                 -0.004115                 -0.004115        -0.004115  \n",
       "2                 -0.004115                 -0.004115        -0.004115  \n",
       "3                 -0.004115                 -0.004115        -0.004115  \n",
       "4                 -0.004115                 -0.004115        -0.004115  \n",
       "\n",
       "[5 rows x 1666 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaled_features = StandardScaler().fit_transform(X)\n",
    "scaled_features = pd.DataFrame(data=scaled_features)\n",
    "scaled_features.columns= X.columns\n",
    "\n",
    "# Let's see how the data looks after scaling\n",
    "scaled_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data\n",
    "Split into train and validation set\n",
    "Train â€“ what we use to train the model\n",
    "\n",
    "Validation â€“ what we use to evaluate the model\n",
    "\n",
    "Test â€“ data that is unexposed to the model\n",
    "\n",
    "X_train: independent feature data for training the model\n",
    "\n",
    "Y_train: dependent feature data for training the model\n",
    "\n",
    "X_test: independent feature data for testing the model; will be used to predict the target values\n",
    "\n",
    "Y_test: original target values of X_test; We will compare this values with our predicted values.\n",
    " \n",
    "test_size = 0.3: 30% of the data will go for test set and 70% of the data will go for train set\n",
    "\n",
    "random_state = 42: this will fix the split i.e. there will be same split for each time you run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with imbalanced data\n",
    "An imbalanced classification problem is an example of a classification problem where the distribution of examples across the known classes is biased or skewed ( let us look only at binary classification)\n",
    "\n",
    "Imbalance can occur due to:\n",
    "\n",
    "Biased sampling â€“ E.g., Sampling only from a single geographic location\n",
    "Nature of the problem statement â€“ E.g., any fraudulent transactions like credit card frauds, etc.\n",
    "The imbalance could be\n",
    "\n",
    "Slight Imbalance (gender distribution â€“ 60% male; 40% female)\n",
    "Severe Imbalance (claims prediction in insurance)\n",
    "Terms (Minority class - that has few examples; Majority class - that has many examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over sampling minority class\n",
    "Oversampling can be defined as adding more copies of the minority class. In other words, we are creating artificial/synthetic data of the minority class (or group). Oversampling could be a good choice when you donâ€™t have a lot of data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'resample' is located under sklearn.utils\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# concatenate training data back together\n",
    "train_data = pd.concat([X_train, Y_train], axis = 1)\n",
    "\n",
    "# separate minority and majority class\n",
    "not_fraud = train_data[train_data.isFraud==0]\n",
    "fraud = train_data[train_data.isFraud==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsample minority; we are oversampling the minority class to match the number of majority classs\n",
    "fraud_upsampled = resample(fraud,\n",
    "                           replace = True, # Sample with replacement\n",
    "                           n_samples = len(not_fraud), # Match number in majority class\n",
    "                           random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    39942\n",
       "1    39942\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's check the classes count\n",
    "upsampled.isFraud.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice here after resampling we have an equal ratio of data points for each class!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under sampling majority class\n",
    "Undersampling can be defined as removing some observations of the majority class. Undersampling can be a good choice when you have a ton of data -think millions of rows. But a drawback is that we are removing information that may be valuable. This could lead to underfitting and poor generalization to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are still using our separated class i.e. fraud and not_fraud from above\n",
    "# Again we are removing the observations of the majority class to mathch the number of minority class\n",
    "# downsample majority\n",
    "not_fraud_downsampled = resample(not_fraud,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(fraud), # match minority n\n",
    "                                random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([not_fraud_downsampled, fraud])    # Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1395\n",
       "1    1395\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the classes counts\n",
    "downsampled.isFraud.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have an equal ratio of fraud to not fraud data points, but in this case \n",
    "\n",
    "a much smaller quantity of data to train the model on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
